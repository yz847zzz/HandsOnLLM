{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-25T03:25:45.358856Z",
     "start_time": "2025-02-25T03:25:41.825949Z"
    }
   },
   "source": [
    "from d2l import torch\n",
    "# use translation2019zh dataset to build a translator help translate from english to chinese\n",
    "# 220k in the training data, 29k as validation sets.  test sets is test sets\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import json\n",
    "\n",
    "\n",
    "max_dataset_size = 220000\n",
    "train_set_size =   200000\n",
    "valid_set_size =    20000\n",
    "\n",
    "class TRANS(Dataset):\n",
    "    def __init__(self,data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "\n",
    "    def load_data(self,data_file):\n",
    "        Data = {}\n",
    "        with open(data_file,'rt',encoding='utf-8') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                if idx >= max_dataset_size:\n",
    "                    break\n",
    "                sample = json.loads(line.strip())\n",
    "                Data[idx] = sample\n",
    "            return Data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "data = TRANS('data/translation2019zh/translation2019zh_train.json')\n",
    "train_data, valid_data = random_split(data, [train_set_size, valid_set_size])\n",
    "test_data = TRANS('data/translation2019zh/translation2019zh_valid.json')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:25:45.390864Z",
     "start_time": "2025-02-25T03:25:45.370862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'train set size: {len(train_data)}')\n",
    "print(f'valid set size: {len(valid_data)}')\n",
    "print(f'test set size: {len(test_data)}')\n",
    "print(next(iter(train_data)))"
   ],
   "id": "1ad6a4a23416952f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 200000\n",
      "valid set size: 20000\n",
      "test set size: 39323\n",
      "{'english': 'In this paper, calculation of load performance of a 28V, 35A claw-pole alternator is presented using three dimensional finite element method with tetrahedral edge elements.', 'chinese': '本文用四面体棱单元三维有限元方法计算一台28V，35A汽车用爪 极 发电机负载特性。'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:25:46.622488Z",
     "start_time": "2025-02-25T03:25:45.609466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use pretrained tokenizer to encode the src and trg\n",
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "id": "8d9768114e76df67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\d2l\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:25:46.653282Z",
     "start_time": "2025-02-25T03:25:46.639488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zh_sentence = train_data[0][\"chinese\"]\n",
    "en_sentence = train_data[0][\"english\"]\n",
    "inputs = tokenizer(zh_sentence)\n",
    "targets = tokenizer(text_target = en_sentence)"
   ],
   "id": "a31f534a219b67c3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:25:46.684283Z",
     "start_time": "2025-02-25T03:25:46.670282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wrong_targets = tokenizer(en_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(targets[\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))"
   ],
   "id": "aee04c4c873f41e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '本文', '用', '四', '面', '体', '棱', '单元', '三', '维', '有限', '元', '方法', '计算', '一台', '28', 'V', ',', '35', 'A', '汽车', '用', '爪', '▁', '极', '▁', '发电机', '负', '载', '特性', '。', '</s>']\n",
      "['▁In', '▁this', '▁paper', ',', '▁calculation', '▁of', '▁load', '▁performance', '▁of', '▁a', '▁28', 'V', ',', '▁35', 'A', '▁claw', '-', 'pol', 'e', '▁alter', 'n', 'ator', '▁is', '▁presented', '▁using', '▁three', '▁', 'dimensional', '▁finite', '▁element', '▁method', '▁with', '▁tetra', 'h', 'ed', 'ral', '▁edge', '▁elements', '.', '</s>']\n",
      "['▁In', '▁this', '▁', 'pa', 'per', ',', '▁c', 'al', 'c', 'ul', 'ation', '▁of', '▁', 'lo', 'ad', '▁', 'per', 'f', 'or', 'man', 'ce', '▁of', '▁a', '▁', '28', 'V', ',', '▁35', 'A', '▁c', 'law', '-', 'po', 'le', '▁al', 'ter', 'na', 'tor', '▁is', '▁pre', 'sen', 'ted', '▁', 'us', 'ing', '▁th', 'ree', '▁d', 'im', 'ens', 'ion', 'al', '▁f', 'in', 'ite', '▁', 'e', 'le', 'ment', '▁me', 'th', 'od', '▁with', '▁', 'te', 'tra', 'he', 'dr', 'al', '▁', 'ed', 'ge', '▁', 'e', 'le', 'ment', 's', '.', '</s>']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:30.691037Z",
     "start_time": "2025-02-24T21:31:30.678037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#structure the input and output\n",
    "import torch\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "inputs = [train_data[s_idx][\"chinese\"] for s_idx in range(4)]\n",
    "targets =  [train_data[s_idx][\"english\"] for s_idx in range(4)]\n",
    "\n",
    "model_inputs = tokenizer(inputs,\n",
    "                         padding=True,\n",
    "                         max_length=max_input_length,\n",
    "                         truncation=True,\n",
    "                         return_tensors=\"pt\"\n",
    "                         )\n",
    "labels = tokenizer(text_target=targets,\n",
    "                   padding=True,\n",
    "                    max_length=max_target_length,\n",
    "                   truncation=True,\n",
    "                   return_tensors=\"pt\")[\"input_ids\"]\n",
    "# padding value set to -100\n",
    "end_token_index = torch.where(labels == tokenizer.eos_token_id)[1] # eos_token_id will return you the </s> token (a special token added at the end), then we assign all value after it(padding) as -100\n",
    "for idx, end_idx in enumerate(end_token_index):\n",
    "    labels[idx][end_idx+1:] = -100\n",
    "print('batch_X shape:', {k: v.shape for k, v in model_inputs.items()})\n",
    "print('batch_y shape:', labels.shape)\n",
    "print(model_inputs)\n",
    "print(labels)\n",
    "\n"
   ],
   "id": "68c135df90bc0d8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([4, 27]), 'attention_mask': torch.Size([4, 27])}\n",
      "batch_y shape: torch.Size([4, 33])\n",
      "{'input_ids': tensor([[ 1244,     2, 29041,     2,  3818, 38422,  8932,     2,   854,  4812,\n",
      "         18852,  3156,   636,    31,  4623,  1865, 16171,     2,  1295,   128,\n",
      "          3598,   378, 46980,    55,  3265,     9,     0],\n",
      "        [ 4336,     5,   155,  2455,  5213, 14710,    55,     5, 18058, 14293,\n",
      "           230,    69,  2847, 12356,     5,     0, 65000, 65000, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000],\n",
      "        [ 4483,   311, 29197,     2, 20408,  7381,   421,  2507,     2,   242,\n",
      "          4383,   850,  3562, 11789,  4485,     9,     0, 65000, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000],\n",
      "        [20440,  1049,   636,  5890,    35,   230,  1017, 32827,     2,  3213,\n",
      "          3009, 11861,  1865,   314,  3209,    11,     9,     0, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "tensor([[   24,   414,  1062,     2,  1385,     2,     3,  8823, 61831,   104,\n",
      "           325,    29,  8905,   325,    19,   174, 25001,     4,   368,  1510,\n",
      "             8,  1710,  7144,    10,   216,    14,   624,  5401, 48225,    84,\n",
      "           472,     5,     0],\n",
      "        [18849,     2,   356,  1391,    21,    22,    32,  1320,     5, 16607,\n",
      "            15, 10827,    21,   294,   237,    57, 46594,  1653,     5,     0,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100],\n",
      "        [ 3525,   161,    30,   179,  4995,     6,   161,    30,  2028, 33831,\n",
      "           161,  8622,  1653,   296,    10,     3,  6504,  3599,     5,     0,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100],\n",
      "        [ 5713,  1032,   211,  3991,    35,   140,    44,  6508,     8,   488,\n",
      "           124,    14,  5887,    50, 41980,     5,     0,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100]])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:26:52.575204Z",
     "start_time": "2025-02-25T03:26:51.599328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "max_length = 128\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    batch_inputs, batch_targets = [], []\n",
    "    for sample in batch_samples:\n",
    "        batch_inputs.append(sample['chinese'])\n",
    "        batch_targets.append(sample['english'])\n",
    "    batch_data = tokenizer(\n",
    "        batch_inputs,\n",
    "        text_target=batch_targets,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(batch_data['labels'])\n",
    "    end_token_index = torch.where(batch_data['labels'] == tokenizer.eos_token_id)[1]\n",
    "    for idx, end_idx in enumerate(end_token_index):\n",
    "        batch_data['labels'][idx][end_idx+1:] = -100\n",
    "    return batch_data\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=collote_fn)"
   ],
   "id": "242acf57f568eb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:44.433470Z",
     "start_time": "2025-02-24T21:31:44.373957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch)"
   ],
   "id": "fefdb22c07ad54a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
      "batch shape: {'input_ids': torch.Size([32, 56]), 'attention_mask': torch.Size([32, 56]), 'labels': torch.Size([32, 45]), 'decoder_input_ids': torch.Size([32, 45])}\n",
      "{'input_ids': tensor([[    7, 19741, 17451,  ..., 65000, 65000, 65000],\n",
      "        [    7,   577,  7686,  ..., 65000, 65000, 65000],\n",
      "        [  196,  7053,  3879,  ..., 65000, 65000, 65000],\n",
      "        ...,\n",
      "        [ 3060,     2, 11865,  ..., 65000, 65000, 65000],\n",
      "        [ 1001,    31,   185,  ..., 65000, 65000, 65000],\n",
      "        [    7,  2620,  4829,  ..., 65000, 65000, 65000]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[33710, 53221,    30,  ...,  -100,  -100,  -100],\n",
      "        [   24,  3508,     8,  ...,  -100,  -100,  -100],\n",
      "        [   38,   871, 48994,  ...,     0,  -100,  -100],\n",
      "        ...,\n",
      "        [  393,   484,     2,  ...,  -100,  -100,  -100],\n",
      "        [   66,   692,  2489,  ...,  -100,  -100,  -100],\n",
      "        [16591,   456,  6367,  ...,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[65000, 33710, 53221,  ..., 65000, 65000, 65000],\n",
      "        [65000,    24,  3508,  ..., 65000, 65000, 65000],\n",
      "        [65000,    38,   871,  ...,     5,     0, 65000],\n",
      "        ...,\n",
      "        [65000,   393,   484,  ..., 65000, 65000, 65000],\n",
      "        [65000,    66,   692,  ..., 65000, 65000, 65000],\n",
      "        [65000, 16591,   456,  ..., 65000, 65000, 65000]])}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:46.724474Z",
     "start_time": "2025-02-24T21:31:45.852272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inside the AutoModelSeq2Seq:\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "from transformers.models.marian import MarianPreTrainedModel, MarianModel\n",
    "class MarianForMT(MarianPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = MarianModel(config)\n",
    "        target_vocab_size = config.decoder_vocab_size\n",
    "        self.register_buffer(\"final_logits_bias\", torch.zeros((1, target_vocab_size)))\n",
    "        self.lm_head = nn.Linear(config.d_model, target_vocab_size, bias=False)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(**x)\n",
    "        sequence_output = output.last_hidden_state\n",
    "        lm_logits = self.lm_head(sequence_output) + self.final_logits_bias\n",
    "        return lm_logits\n",
    "\n",
    "    def other_func(self):\n",
    "        pass\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "model = MarianForMT.from_pretrained(model_checkpoint, config=config).to(device)\n",
    "print(model)"
   ],
   "id": "4b04e408686e9182",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MarianForMT were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-zh-en and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianForMT(\n",
      "  (model): MarianModel(\n",
      "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
      "    (encoder): MarianEncoder(\n",
      "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianEncoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): SiLU()\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): MarianDecoder(\n",
      "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianDecoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (activation_fn): SiLU()\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:49.995646Z",
     "start_time": "2025-02-24T21:31:49.980648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ],
   "id": "d9209c1d9d53b838",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:51.121134Z",
     "start_time": "2025-02-24T21:31:51.075132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use BLEU to test / validate the model\n",
    "from sacrebleu.metrics import BLEU\n",
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "bad_predictions_1 = [\"This This This This\"]\n",
    "bad_predictions_2 = [\"This plugin\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "bleu = BLEU()\n",
    "print(bleu.corpus_score(predictions, references).score)\n",
    "print(bleu.corpus_score(bad_predictions_1, references).score)\n",
    "print(bleu.corpus_score(bad_predictions_2, references).score) # too short and too bad, will very low"
   ],
   "id": "6ccda7feeedd03a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.750469682990165\n",
      "1.683602693167689\n",
      "0.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:52.449553Z",
     "start_time": "2025-02-24T21:31:52.437219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "predictions = [\n",
    "    \"我在苏州大学学习计算机，苏州大学很美丽。\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [\n",
    "        \"我在环境优美的苏州大学学习计算机。\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "bleu = BLEU(tokenize='zh')\n",
    "print(f'BLEU: {bleu.corpus_score(predictions, references).score}')\n",
    "bleu = BLEU()\n",
    "print(f'wrong BLEU: {bleu.corpus_score(predictions, references).score}') # should specify the tokenize, otherwize it will defualt use english\n"
   ],
   "id": "61fd765b70b70e28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 45.340106118883256\n",
      "wrong BLEU: 0.0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T21:31:54.744120Z",
     "start_time": "2025-02-24T21:31:53.480203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AutoModelseq2seq also have generate function that can decode the output of the model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "sentence = '你好吗，我正在机场坐着喝可乐，马上就要起飞了'\n",
    "sentence_inputs = tokenizer(sentence, return_tensors='pt').to(device)\n",
    "sentence_generated_tokens = model.generate(sentence_inputs['input_ids'],\n",
    "                                            attention_mask=sentence_inputs['attention_mask'],\n",
    "                                           max_length=128\n",
    "                                            )\n",
    "sentence_decoded_pred = tokenizer.decode(sentence_generated_tokens[0], skip_special_tokens=True)\n",
    "print(sentence_decoded_pred)"
   ],
   "id": "61a0808d90600717",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\d2l\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you? I'm sitting at the airport drinking Coke. I'm about to take off.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T22:36:09.952332Z",
     "start_time": "2025-02-24T22:36:09.938332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "import numpy as np\n",
    "bleu = BLEU()\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    preds, labels = [], []\n",
    "\n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_length,\n",
    "            ).cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [[label.strip()] for label in decoded_labels]\n",
    "    return bleu.corpus_score(preds, labels).score"
   ],
   "id": "f6fb3fa47fed07da",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T00:17:22.465850Z",
     "start_time": "2025-02-24T22:36:45.135150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train and test and save model\n",
    "from transformers import AdamW, get_scheduler\n",
    "learning_rate = 2e-5\n",
    "epochs = 3\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_dataloader) * epochs\n",
    ")\n",
    "\n",
    "total_loss = 0\n",
    "best_bleu = 0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}/{epochs}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_bleu = test_loop(valid_dataloader, model)\n",
    "    print(f\"BLEU: {valid_bleu:>0.2f}\\n\")\n",
    "    if valid_bleu > best_bleu:\n",
    "        best_bleu = valid_bleu\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'epoch_{t+1}_valid_bleu_{valid_bleu:0.2f}_model_weights.bin')\n",
    "print(\"Done!\")\n"
   ],
   "id": "d8571f8a0323ea53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eae75b622d0b420b9a01c70921c36d2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c95ff1fd3dc45c6b2e91e47be94585a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 39.20\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22b662ff41ce45e2aa0c16dfb051837a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "039aa4964a004e6e8b9e2422f3f94861"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 41.29\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/6250 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b14ff34db0a84b5e9446177206982ca1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f1858ebeb494b87b1c37cef19c15baa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 41.29\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:26:56.491451Z",
     "start_time": "2025-02-25T03:26:56.387848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_data = TRANS('data/translation2019zh/translation2019zh_valid.json')\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collote_fn)\n"
   ],
   "id": "14d838836a6b6383",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:33:48.274341Z",
     "start_time": "2025-02-25T03:33:47.132082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "model.load_state_dict(torch.load('epoch_2_valid_bleu_41.29_model_weights.bin'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('evaluating on test set...')\n",
    "    sources, preds, labels = [], [], []\n",
    "    for batch_data in tqdm(test_dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            batch_data[\"input_ids\"],\n",
    "            attention_mask=batch_data[\"attention_mask\"],\n",
    "            max_length=max_length,\n",
    "        ).cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            batch_data[\"input_ids\"].cpu().numpy(),\n",
    "            skip_special_tokens=True,\n",
    "            use_source_tokenizer=True\n",
    "        )\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [[label.strip()] for label in decoded_labels]\n",
    "    bleu_score = bleu.corpus_score(preds, labels).score\n",
    "    print(f\"Test BLEU: {bleu_score:>0.2f}\\n\")\n",
    "    results = []\n",
    "    print('saving predicted results...')\n",
    "    for source, pred, label in zip(sources, preds, labels):\n",
    "        results.append({\n",
    "            \"sentence\": source,\n",
    "            \"prediction\": pred,\n",
    "            \"translation\": label[0]\n",
    "        })\n",
    "    with open('test_data_pred.json', 'wt', encoding='utf-8') as f:\n",
    "        for exapmle_result in results:\n",
    "            f.write(json.dumps(exapmle_result, ensure_ascii=False) + '\\n')"
   ],
   "id": "c353f788e5519824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1229 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3ab33116ee5434cae88de7bd5a67a9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_data \u001B[38;5;129;01min\u001B[39;00m tqdm(test_dataloader):\n\u001B[0;32m     12\u001B[0m     batch_data \u001B[38;5;241m=\u001B[39m batch_data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 13\u001B[0m     generated_tokens \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattention_mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     18\u001B[0m     label_tokens \u001B[38;5;241m=\u001B[39m batch_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     20\u001B[0m     decoded_sources \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(\n\u001B[0;32m     21\u001B[0m         batch_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy(),\n\u001B[0;32m     22\u001B[0m         skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     23\u001B[0m         use_source_tokenizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     )\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\transformers\\generation\\utils.py:2254\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   2246\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[0;32m   2247\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   2248\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   2249\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[0;32m   2250\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   2251\u001B[0m     )\n\u001B[0;32m   2253\u001B[0m     \u001B[38;5;66;03m# 13. run beam sample\u001B[39;00m\n\u001B[1;32m-> 2254\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_beam_search(\n\u001B[0;32m   2255\u001B[0m         input_ids,\n\u001B[0;32m   2256\u001B[0m         beam_scorer,\n\u001B[0;32m   2257\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   2258\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[0;32m   2259\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[0;32m   2260\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[0;32m   2261\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   2262\u001B[0m     )\n\u001B[0;32m   2264\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGROUP_BEAM_SEARCH:\n\u001B[0;32m   2265\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[0;32m   2266\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[0;32m   2267\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   2268\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2274\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[0;32m   2275\u001B[0m     )\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\transformers\\generation\\utils.py:3531\u001B[0m, in \u001B[0;36mGenerationMixin._beam_search\u001B[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[0;32m   3528\u001B[0m next_tokens \u001B[38;5;241m=\u001B[39m next_tokens \u001B[38;5;241m%\u001B[39m vocab_size\n\u001B[0;32m   3530\u001B[0m \u001B[38;5;66;03m# stateless\u001B[39;00m\n\u001B[1;32m-> 3531\u001B[0m beam_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mbeam_scorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3532\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnext_token_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3534\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnext_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnext_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3536\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3537\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeam_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeam_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_prompt_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_prompt_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3540\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3542\u001B[0m beam_scores \u001B[38;5;241m=\u001B[39m beam_outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext_beam_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   3543\u001B[0m beam_next_tokens \u001B[38;5;241m=\u001B[39m beam_outputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext_beam_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\transformers\\generation\\beam_search.py:273\u001B[0m, in \u001B[0;36mBeamSearchScorer.process\u001B[1;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001B[0m\n\u001B[0;32m    271\u001B[0m batch_beam_idx \u001B[38;5;241m=\u001B[39m batch_idx \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup_size \u001B[38;5;241m+\u001B[39m next_index\n\u001B[0;32m    272\u001B[0m \u001B[38;5;66;03m# add to generated hypotheses if end of sentence\u001B[39;00m\n\u001B[1;32m--> 273\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (eos_token_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[43mnext_token\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01min\u001B[39;00m eos_token_id):\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;66;03m# if beam_token does not belong to top num_beams tokens, it should not be added\u001B[39;00m\n\u001B[0;32m    275\u001B[0m     is_beam_token_worse_than_top_num_beams \u001B[38;5;241m=\u001B[39m beam_token_rank \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroup_size\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_beam_token_worse_than_top_num_beams:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:34:18.606201Z",
     "start_time": "2025-02-25T03:34:18.220200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#decoder study:\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ],
   "id": "eb5c707816c97033",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:35:07.045853Z",
     "start_time": "2025-02-25T03:35:05.563964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='pt')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ],
   "id": "a26cff199c4dc735",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
      "\n",
      "I'm not sure if I'll\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:35:58.303671Z",
     "start_time": "2025-02-25T03:35:56.369241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#beam search output:\n",
    "beam_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ],
   "id": "3d55774b9df4353a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:36:37.630659Z",
     "start_time": "2025-02-25T03:36:35.791090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set no_repeat_ngram_size to 2\n",
    "beam_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ],
   "id": "9361069250e74513",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a break\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:37:15.304231Z",
     "start_time": "2025-02-25T03:37:13.476491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beam_outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=3,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ],
   "id": "c96cbcfd7a5aabd1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
      "\n",
      "\n",
      "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
      "\n",
      "\n",
      "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:38:19.094752Z",
     "start_time": "2025-02-25T03:38:17.524342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#random sampling\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ],
   "id": "a0d718fa6aec9975",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog,\" she says. \"You get a lot of love and eventually a great guy comes in with your national credentials. He gives you a virtual identity as a dog owner. You celebrate by smiling and laughing, and then\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:39:47.916903Z",
     "start_time": "2025-02-25T03:39:46.394525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=0,\n",
    "    temperature=0.6\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ],
   "id": "f14b4f44f14cca67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, so I'm not sure if she's a little bit of a sweetheart. She has a sweet chestnut head, and I'm hoping she doesn't get it in her mouth. She's a little bit\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:42:50.354869Z",
     "start_time": "2025-02-25T03:42:48.800620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#top_k sampling\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ],
   "id": "49c912aff4bae2a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog,\" she says. \"You get a lot of love and support from people you can't really talk to because you don't know what they're thinking. It's a very different feeling to be in a shelter because\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T03:44:39.440341Z",
     "start_time": "2025-02-25T03:44:37.912435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=50,\n",
    "    top_p=0.9,\n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ],
   "id": "22059b2fc98d4417",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog,\" she says. \"You get a lot of love and support from people you can't really talk to because you don't know why and it doesn't help much. We'd say to her 'Do you have\n",
      "\n",
      "\n",
      "1: I enjoy walking with my cute dog. I would also like to see a new feature for our cats, the cute bear, that is called 'Spend Your Sunday, Beating A Cat'.\n",
      "\n",
      "So much so that I have no idea how\n",
      "\n",
      "\n",
      "2: I enjoy walking with my cute dog, but I would definitely encourage anyone that will meet me in person to make a photo of me. I'm in the middle of a crazy project about this puppy and so I'm hoping that we can start doing one\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5dedb04dda851695"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
